# ğŸ›¡ï¸ VANGUARD: Versatile Aggregation for Networked Governance Using Unified AI with Reinforced Decisionin

![Dashboard](https://raw.githubusercontent.com/Arjun4522/VanguardProd/main/snapshots/dash.jpeg)


**VANGUARD** is an advanced, modular network intrusion detection and governance system that integrates cutting-edge techniques in artificial intelligence (AI), federated learning, differential privacy (DP), and blockchain-inspired aggregation mechanisms to ensure real-time, scalable, and secure detection of network anomalies and cyber threats.

The system is designed to optimize the detection of malicious activities in highly distributed network environments, such as enterprise infrastructures or Internet of Things (IoT) networks. It leverages a combination of federated learning, reinforcement learning (RL), multi-party aggregation, and differential privacy to create a robust and adaptive defense system that evolves and adapts as new threats emerge, all while preserving the privacy of the data it processes.

---

## ğŸ¯ Key Features and Components

### ğŸ§  Global and Local Model Architecture
- **ğŸŒ Global Model**: A Random Forest model is initially trained on a large, public dataset (such as the CIC-IDS-2017 collection). This global model acts as a foundational intrusion detection engine.
- **ğŸ¯ Local Fine-Tuning**: The model is distributed to local nodes (such as remote devices or edge servers) where it undergoes fine-tuning. The fine-tuning process incorporates reinforcement learning (RL) for dynamic decision-making and uses Nash Bargaining to optimally allocate resources for differential privacy budget.

### ğŸ”’ Differential Privacy (DP) and Privacy-Preserving Learning
To ensure the privacy of data used in training, the system introduces Gaussian noise into the fine-tuning process. This ensures the differential privacy of the individual data contributors and prevents leakage of sensitive information.

### ğŸ¤ Federated Learning Framework
- **ğŸ“¡ Federated Learning** is employed to train machine learning models across distributed nodes without requiring the data to leave individual systems. This helps maintain data privacy and minimizes the need for expensive central storage or computation.
- The fine-tuned local models are aggregated back into the global model using a blockchain-inspired, reputation-based aggregation mechanism called **Multi-Krum**, which ensures robust aggregation even in the presence of Byzantine failures (faulty or malicious nodes).

### ğŸš¨ Anomaly Detection with Random Forest Classifier
The system's core detection engine is based on a **Random Forest** algorithm, which is trained and continuously updated on network traffic patterns. This allows the system to detect anomalies (such as DDoS attacks, port scanning, or unauthorized access) effectively.

### âš¡ Real-Time Data Streaming and Monitoring
- The system employs a **ğŸ”„ Kafka-based** architecture for real-time message streaming and event processing. Network traffic data is captured and transmitted using **Scapy** for packet capture and **Kafka** for data streaming.
- In addition, **ğŸ“Š Prometheus** and **ğŸ“ˆ Grafana** are used for continuous monitoring of network performance and ML model metrics, providing a dashboard that visualizes both the network traffic and anomaly detection results in real time.

### ğŸ›¡ï¸ Secure Aggregation and Byzantine Fault Tolerance (BFT)
The system ensures secure aggregation using **Byzantine Fault Tolerance (BFT)** mechanisms, which provide resilience against faulty nodes and ensure that malicious actions do not corrupt the global model.

The use of **Apache Kafka** enables secure communication between nodes, ensuring the efficient transmission of models and updates.

### ğŸŒ API and Real-Time Analytics
The system is integrated with a **FastAPI** backend that provides RESTful API access for querying system status, retrieving real-time anomaly data, and managing model updates.

Additionally, **âš¡ Redis** is used for fast, in-memory data storage, providing efficient access to time-series data and ensuring low-latency performance for real-time analysis.

### ğŸ’» Front-End Visualization
The **âš›ï¸ React.js**-based frontend provides an intuitive, user-friendly dashboard for visualizing network traffic, model predictions, and anomaly detection results.

This dashboard includes dynamic visualizations of network data and statistics, using libraries like **React Force Graph** to display network topologies and traffic flows.

---

## ğŸ› ï¸ Technical Stack

| Category | Technologies |
|----------|-------------|
| **Backend** | ğŸ Python, ğŸš€ FastAPI, ğŸ”„ Kafka, ğŸ•·ï¸ Scapy, âš¡ Redis, ğŸ˜ PostgreSQL, ğŸ“Š Prometheus, ğŸ“ˆ Grafana |
| **Machine Learning** | ğŸŒ³ Random Forest, ğŸ¤– Reinforcement Learning, ğŸ¤ Federated Learning, ğŸ”’ Differential Privacy |
| **Frontend** | âš›ï¸ React.js, âš¡ Vite, ğŸ¨ Material UI, ğŸŒ React Force Graph |
| **Distributed Computing** | ğŸ¤ Federated Learning, ğŸ”„ Multi-Krum Aggregation, ğŸ›¡ï¸ Byzantine Fault Tolerance (BFT) |
| **Data Streaming** | ğŸ”„ Kafka |
| **Time-Series Data** | â° RedisTimeSeries, ğŸ“Š Prometheus |
| **Deployment** | ğŸ³ Docker, â˜¸ï¸ Kubernetes (optional) |

---

## ğŸ¯ Use Cases

- **ğŸ¢ Enterprise Network Security**: VANGUARD is ideal for large-scale network infrastructures that require real-time anomaly detection and adaptive learning to protect against evolving threats.
- **ğŸ“± IoT Security**: The system's federated learning architecture is well-suited for IoT networks, where distributed devices need local training while preserving the privacy of sensitive data.
- **â˜ï¸ Cloud Security**: VANGUARD can be deployed in cloud environments for continuous monitoring and anomaly detection, ensuring the security of cloud-hosted services and applications.
- **ğŸ”’ Privacy-Preserving Machine Learning**: VANGUARD's use of differential privacy ensures that even sensitive user data can be used for machine learning without compromising privacy.

---

## ğŸš€ Project Setup

### 1. ğŸ“¥ Clone Repository

```bash
git clone git@github.com:Arjun4522/VanguardProd.git
cd VanguardProd
```

### 2. ğŸ Create and Activate Virtual Environment

```bash
# Create virtual environment
python3 -m venv vanguard_env

# Activate environment
source vanguard_env/bin/activate
```

### 3. ğŸ“¦ Download and Setup Kafka Binaries

```bash
# Navigate to production folder
cd backend/production

# Download and extract binaries
wget kafka_2.13-3.6.1.tar.gz
tar -xvzf kafka_2.13-3.6.1.tar.gz
```

---

## âš™ï¸ Backend Setup

### 1. ğŸ“‹ Install Dependencies

```bash
pip install -r backend/production/requirements.txt
```

### 2. ğŸ”„ Start Kafka and Zookeeper

```bash
# Start Zookeeper server
cd backend/production/kafka_2.13-3.6.1
bin/zookeeper-server-start.sh config/zookeeper.properties

# In a new terminal start kafka service (keep Zookeeper running)
bin/kafka-server-start.sh config/server.properties

# Create topic 'network-flows'
bin/kafka-topics.sh --create \
  --topic network-flows \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 1

# Test topic creation
bin/kafka-topics.sh --list --bootstrap-server localhost:9092
```

### 3. ğŸš€ Start Kafka Producers and Consumers

#### 3.1 ğŸŒ Capture and Produce Network Flows

```bash
# Still inside vanguard_env
sudo python3 backend/production/kafka_produce_capture.py \
  -i wlo1 \
  --kafka-brokers "localhost:9092" \
  --kafka-topic "network-flows" \
  --log-level INFO
```

#### 3.2 ğŸ—„ï¸ Store into PostgreSQL

```bash
sudo python3 backend/production/kafka_consume_db.py \
  --db-host localhost \
  --db-port 5432 \
  --db-name netflows \
  --db-user network_admin \
  --db-password securepassword123 \
  --kafka-brokers localhost:9092 \
  --kafka-topic network-flows \
  --log-level INFO
```

#### 3.3 ğŸŒ Start API Server (FastAPI + WebSocket)

```bash
uvicorn kafka_consume_api:app --port 8888
```

#### 3.4 âš¡ Run RedisTimeSeries in Docker

```bash
# Run RedisTimeSeries in Docker
docker run -d --name redis-ts -p 6379:6379 redislabs/redistimeseries

# Start Redis consumer
python3 backend/production/kafka_consumer_redis.py \
  --redis-host localhost \
  --redis-port 6379 \
  --kafka-brokers localhost:9092 \
  --kafka-topic network-flows \
  --log-level INFO
```

### 4. ğŸ” Kafka Console Consumer (Optional for Debugging)

```bash
cd backend/production/kafka_2.13-3.6.1
bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic network-flows \
  --from-beginning
```

---

## ğŸ’» Frontend Setup

### 1. ğŸ“ Navigate to the Frontend Directory

```bash
cd ids-dashboard
```

### 2. ğŸ“¦ Install Frontend Dependencies

```bash
npm install
```

### 3. ğŸš€ Run the Development Server

```bash
npm run dev
```

---

## ğŸ“Š System Architecture

```mermaid
graph TB
    A[ğŸŒ Network Traffic] --> B[ğŸ•·ï¸ Scapy Capture]
    B --> C[ğŸ”„ Kafka Producer]
    C --> D[ğŸ“¨ Kafka Topic: network-flows]
    
    D --> E[ğŸ—„ï¸ PostgreSQL Consumer]
    D --> F[âš¡ Redis Consumer]
    D --> G[ğŸŒ FastAPI Consumer]
    
    E --> H[ğŸ˜ PostgreSQL Database]
    F --> I[âš¡ RedisTimeSeries]
    G --> J[ğŸ“¡ WebSocket API]
    
    K[ğŸ§  ML Model] --> L[ğŸ¤– Anomaly Detection]
    L --> M[ğŸš¨ Alert System]
    M --> D
    
    J --> N[âš›ï¸ React Dashboard]
    I --> N
    H --> N
```

---

## ğŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. ğŸ´ Fork the repository
2. ğŸŒ¿ Create a feature branch (`git checkout -b feature/amazing-feature`)
3. ğŸ’¾ Commit your changes (`git commit -m 'Add some amazing feature'`)
4. ğŸ“¤ Push to the branch (`git push origin feature/amazing-feature`)
5. ğŸ”„ Open a Pull Request

---

